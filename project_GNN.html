<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Robust GNN Research</title>
    <link rel="stylesheet" href="css/all.min.css" />
    <link rel="stylesheet" href="css/bootstrap.min.css" />
    <style>
      body {
        font-family: 'Open Sans', sans-serif;
        background-color: #f8f9fa;
        color: #333;
        padding: 20px;
      }

      .content {
        max-width: 800px;
        margin: 0 auto;
      }

      h1 {
        font-size: 2.5rem;
        color: #007bff;
        text-align: center;
        margin-bottom: 20px;
      }

      h2 {
        font-size: 1.8rem;
        color: #333;
        margin-bottom: 15px;
      }

      p {
        font-size: 1.2rem;
        line-height: 1.6;
        margin-bottom: 20px;
      }

      ul {
        font-size: 1.2rem;
        line-height: 1.6;
        margin-left: 20px;
        margin-bottom: 20px;
      }

      img {
        width: 100%;
        margin-bottom: 20px;
        border-radius: 10px;
      }
    </style>
  </head>
  <body>
    <div class="content">
      <h1>Robust GNN against Label Flipping Attack</h1>
      <p>
        This project focused on improving the robustness of Graph Neural Networks (GNNs) against label flipping attacks. 
        By applying p-Laplacian, local characteristics were nonlinearly reflected, leading to better performance in 
        node label prediction tasks.
      </p>

      <h2>Key Contributions</h2>
      <ul>
        <li>Applied p-Laplacian to model nonlinear local graph characteristics effectively.</li>
        <li>Improved node label prediction performance by ~5% under adversarial conditions.</li>
        <li>Validated the proposed method using extensive experiments on benchmark datasets.</li>
      </ul>

      <h2>Research Highlights</h2>
      <p>The following steps were critical to the success of this project:</p>
      <ol>
        <li>Analyzed the impact of label flipping attacks on graph structures and node prediction performance.</li>
        <li>Incorporated p-Laplacian into the GNN framework to enhance robustness against local perturbations.</li>
        <li>Evaluated the model on standard graph datasets to measure improvements in accuracy and robustness.</li>
      </ol>

      <h2>Visual Insights</h2>
      <p>Below are key visuals and results from the project:</p>
      <img src="img/gnn_workflow.png" alt="GNN Workflow" />
      <img src="img/gnn_results.png" alt="GNN Results" />

      <h2>Conclusion</h2>
      <p>
        This project demonstrated the effectiveness of p-Laplacian-based approaches in enhancing GNN robustness against 
        label flipping attacks. The proposed method achieved consistent improvements in node label prediction accuracy 
        and can be extended to other adversarial attack scenarios.
      </p>
    </div>
  </body>
</html>
